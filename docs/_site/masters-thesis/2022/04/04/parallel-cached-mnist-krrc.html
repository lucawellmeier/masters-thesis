<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Parallel and cached computations for MNIST kernel ridge regression experiment | Luca Wellmeier</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Parallel and cached computations for MNIST kernel ridge regression experiment" />
<meta name="author" content="Luca Wellmeier" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is a reproduction of a numerical experiment presented in the 2019 paper Just Interpolate: Kernel “Ridgeless” Regression Can Generalize by Tengyuan Liang and Alexander Rakhlin. They argue that interpolating, i.e. having a very small to zero training error, can perform well under certain circumstances, and they analyze asymptotically when this happens in the case of kernel ridge regression. The usage of kernels gives enough freedom to allow interpolation, which is expected to happen in kernel ridge regression if we don’t regularize by setting $\alpha = 0$ (“ridgeless”). I will go into the details of how to see this phenomenon using scikit-learn, exploring parallel computations and smart caching of intermediate products in long computations." />
<meta property="og:description" content="This is a reproduction of a numerical experiment presented in the 2019 paper Just Interpolate: Kernel “Ridgeless” Regression Can Generalize by Tengyuan Liang and Alexander Rakhlin. They argue that interpolating, i.e. having a very small to zero training error, can perform well under certain circumstances, and they analyze asymptotically when this happens in the case of kernel ridge regression. The usage of kernels gives enough freedom to allow interpolation, which is expected to happen in kernel ridge regression if we don’t regularize by setting $\alpha = 0$ (“ridgeless”). I will go into the details of how to see this phenomenon using scikit-learn, exploring parallel computations and smart caching of intermediate products in long computations." />
<link rel="canonical" href="http://localhost:4000/masters-thesis/2022/04/04/parallel-cached-mnist-krrc.html" />
<meta property="og:url" content="http://localhost:4000/masters-thesis/2022/04/04/parallel-cached-mnist-krrc.html" />
<meta property="og:site_name" content="Luca Wellmeier" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-04-04T00:00:00+02:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Parallel and cached computations for MNIST kernel ridge regression experiment" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Luca Wellmeier"},"dateModified":"2022-04-04T00:00:00+02:00","datePublished":"2022-04-04T00:00:00+02:00","description":"This is a reproduction of a numerical experiment presented in the 2019 paper Just Interpolate: Kernel “Ridgeless” Regression Can Generalize by Tengyuan Liang and Alexander Rakhlin. They argue that interpolating, i.e. having a very small to zero training error, can perform well under certain circumstances, and they analyze asymptotically when this happens in the case of kernel ridge regression. The usage of kernels gives enough freedom to allow interpolation, which is expected to happen in kernel ridge regression if we don’t regularize by setting $\\alpha = 0$ (“ridgeless”). I will go into the details of how to see this phenomenon using scikit-learn, exploring parallel computations and smart caching of intermediate products in long computations.","headline":"Parallel and cached computations for MNIST kernel ridge regression experiment","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/masters-thesis/2022/04/04/parallel-cached-mnist-krrc.html"},"url":"http://localhost:4000/masters-thesis/2022/04/04/parallel-cached-mnist-krrc.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Luca Wellmeier" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css" integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js" integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ],
        throwOnError : false
      });
    });
  </script>
  
  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Luca Wellmeier</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/masters-thesis/">Master&#39;s thesis</a></div>
      </nav></div>
</header>
<main class="page-content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Parallel and cached computations for MNIST kernel ridge regression experiment</h1>
    <p class="post-meta"><time class="dt-published" datetime="2022-04-04T00:00:00+02:00" itemprop="datePublished">
        Apr 4, 2022
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>This is a reproduction of a numerical experiment presented in the 2019 paper <a href="https://arxiv.org/abs/1808.00387">Just Interpolate: Kernel “Ridgeless” Regression Can Generalize</a> by Tengyuan Liang and Alexander Rakhlin. They argue that interpolating, i.e. having a very small to zero training error, can perform well under certain circumstances, and they analyze asymptotically when this happens in the case of kernel ridge regression. The usage of kernels gives enough freedom to allow interpolation, which is expected to happen in kernel ridge regression if we don’t regularize by setting $\alpha = 0$ (“ridgeless”). I will go into the details of how to see this phenomenon using <code class="language-plaintext highlighter-rouge">scikit-learn</code>, exploring parallel computations and smart caching of intermediate products in long computations.</p>

<!--more-->

<p>The complete code is available for download from <a href="https://github.com/lucawellmeier/krrc-mnist-smart-cache">this GitHub repo</a>. To run it yourself, you’ll need <code class="language-plaintext highlighter-rouge">Python 3.10</code> and <code class="language-plaintext highlighter-rouge">scikit-learn 1.0.2</code> or compatible versions. My machine is a ThinkPad T450s with Intel Core i7 5600U with 2 cores (4 threads), 2.6 GHz base frequency and 11 GB of RAM running ArchLinux. The timings refer to this.</p>

<p>This is not supposed to be a guide and I do not claim to employ best practices in the field (which I don’t do neither know yet). I am still learning. Please feel free to contact me <a href="mailto:lucwellm@gmail.com">lucwellm@gmail.com</a> for any suggestions, questions, …</p>

<p><strong>Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#the-problem-and-computation-using-scikit-learn" id="markdown-toc-the-problem-and-computation-using-scikit-learn">The Problem and Computation using <code class="language-plaintext highlighter-rouge">scikit-learn</code></a></li>
  <li><a href="#setup-of-parallelism-and-smart-cache-for-the-computations" id="markdown-toc-setup-of-parallelism-and-smart-cache-for-the-computations">Setup of Parallelism and Smart Cache for the Computations</a></li>
  <li><a href="#reproduction-of-figures-of-the-paper" id="markdown-toc-reproduction-of-figures-of-the-paper">Reproduction of Figures of the Paper</a>    <ul>
      <li><a href="#training-and-test-errors" id="markdown-toc-training-and-test-errors">Training and Test Errors</a></li>
      <li><a href="#covariance-and-kernel-spectra" id="markdown-toc-covariance-and-kernel-spectra">Covariance and Kernel Spectra</a></li>
    </ul>
  </li>
</ul>

<h2 id="the-problem-and-computation-using-scikit-learn">The Problem and Computation using <code class="language-plaintext highlighter-rouge">scikit-learn</code></h2>

<p>The challenge is to classify handwritten digits which can be part of either of two classes from the MNIST dataset. This shall be done using kernel ridge regression: we label one digit by 1, the other one by -1, perform the regression on a new unknown drawing and receive a number between -1 and 1, which gives an estimate which class would be closer. The used kernel will be standard Gaussian (radial basis function) and we measure the error with the following metric (called <code class="language-plaintext highlighter-rouge">error_metric</code> in the code below):</p>

\[\frac{\sum_{i=1}^N  (\hat{f}(x_i) - y_i)^2}{\sum_{i=1}^N  (\mathbb{E}[y_i] - y_i)^2}\]

<p>The following code describes how that would generally look like in <code class="language-plaintext highlighter-rouge">scikit-learn</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidge</span>

<span class="k">def</span> <span class="nf">my_error_metric</span><span class="p">(</span><span class="n">Ytrue</span><span class="p">,</span> <span class="n">Ypred</span><span class="p">):</span>
    <span class="n">ybar</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">average</span><span class="p">(</span><span class="n">y_true</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">ybar</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>

<span class="n">digitA</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">digitB</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">Ntrain</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">Ntest</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span>

<span class="c1"># step1: fetch MNIST dataset (this takes a few minutes) and prepare two-class sample
</span><span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s">'mnist_784'</span><span class="p">)</span>
<span class="n">all_digits</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span>  <span class="c1"># normalize; otherwise kernel produces values too close to zero
</span><span class="n">two_class_data</span> <span class="o">=</span> <span class="n">all_digits</span><span class="p">[</span><span class="n">mnist</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">digitA</span><span class="p">)</span> <span class="ow">or</span> <span class="n">mnist</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">digitB</span><span class="p">)]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">all_digits</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">labels</span><span class="p">[</span><span class="n">mnist</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">digitA</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">labels</span><span class="p">[</span><span class="n">mnist</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">digitB</span><span class="p">)]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">labels</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># shuffle and take only what we need
</span><span class="n">N</span> <span class="o">=</span> <span class="n">Ntrain</span> <span class="o">+</span> <span class="n">Ntest</span>
<span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">().</span><span class="n">permutation</span><span class="p">(</span><span class="n">two_class_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">,</span> <span class="n">Ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">two_class_data</span><span class="p">[</span><span class="n">perm</span><span class="p">][:</span><span class="n">N</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">perm</span><span class="p">][:</span><span class="n">N</span><span class="p">],</span> <span class="n">test_size</span><span class="o">=</span><span class="n">Ntest</span><span class="p">)</span>

<span class="c1"># train model and predict
</span><span class="n">model</span> <span class="o">=</span> <span class="n">KernelRidge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'rbf_kernel'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">)</span>
<span class="n">train_error</span> <span class="o">=</span> <span class="n">my_error_metric</span><span class="p">(</span><span class="n">Ytr</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtr</span><span class="p">))</span>
<span class="n">test_error</span> <span class="o">=</span> <span class="n">my_error_metric</span><span class="p">(</span><span class="n">Yte</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte</span><span class="p">))</span>
</code></pre></div></div>

<p>Since we will also consider the spectrum of the kernel matrix, it makes sense to take its computation in our own hands:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">rbf_kernel</span>

<span class="n">train_kernel</span> <span class="o">=</span> <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">)</span>
<span class="n">test_kernel</span> <span class="o">=</span> <span class="n">rbf_kernel</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">)</span>

<span class="c1"># step spectrum
</span><span class="n">spec</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">eig</span><span class="p">(</span><span class="n">train_kernel</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KernelRidge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'precomputed'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_kernel</span><span class="p">)</span>
<span class="n">train_error</span> <span class="o">=</span> <span class="n">my_error_metric</span><span class="p">(</span><span class="n">Ytr</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_kernel</span><span class="p">))</span>
<span class="n">test_error</span> <span class="o">=</span> <span class="n">my_error_metric</span><span class="p">(</span><span class="n">Yte</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_kernel</span><span class="p">))</span>
</code></pre></div></div>

<p>Here’s what we want to compute with <code class="language-plaintext highlighter-rouge">Ntrain = 6000</code> and <code class="language-plaintext highlighter-rouge">Ntest = 2000</code>:</p>

<ul>
  <li>kernel spectrum for all 45 pairs of digits</li>
  <li>covariance spectrum of the image data of all 45 pairs of digits</li>
  <li>both train and test error for all 45 pairs of digits and <code class="language-plaintext highlighter-rouge">alpha = 0, 0.01, 0.02, 0.04, 0.08, 0.1, 0.16, 0.32, 0.64, 1, 1.28</code></li>
</ul>

<p>For reference: each image has size 28 x 28 = 784.</p>

<h2 id="setup-of-parallelism-and-smart-cache-for-the-computations">Setup of Parallelism and Smart Cache for the Computations</h2>

<p>As I was starting to implement and compute, I immediately ran into some quite nasty problems: long computation times, huge amounts of memory and disk space needed. Hence I decided to use this as an opportunity to experiment with parallelism and to develop a sort of “smart cache” that keeps byproducts stored on the disk only as long as they are needed and chooses the next computational steps in an educated way. The final code to compute the above targets would look like this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">dep_cache</span> <span class="kn">import</span> <span class="n">ParallelDependencyCache</span>

<span class="n">cache</span> <span class="o">=</span> <span class="n">ParallelDependencyCache</span><span class="p">(</span><span class="s">'/home/luca/krrc_mnist_cache/'</span><span class="p">)</span>

<span class="n">Ntr</span> <span class="o">=</span> <span class="mi">6000</span>
<span class="n">Nte</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.16</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.28</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">CovSpec</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span><span class="n">Nte</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">))</span>
        <span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">KernelSpec</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span><span class="n">Nte</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
            <span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">Errors</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span><span class="n">Nte</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">alpha</span><span class="p">))</span>

<span class="n">cache</span><span class="p">.</span><span class="n">fetch</span><span class="p">(</span><span class="n">n_threads</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>

<p>The three classes <code class="language-plaintext highlighter-rouge">CovSpec</code>, <code class="language-plaintext highlighter-rouge">KernelSpec</code> and <code class="language-plaintext highlighter-rouge">Errors</code> are subclasses of the class <code class="language-plaintext highlighter-rouge">CachedFile</code> (see <code class="language-plaintext highlighter-rouge">dep_cache.py</code> in the <a href="https://github.com/lucawellmeier/krrc-mnist-smart-cache">repo</a>), which needs them to define parameters, dependencies, computation and save/load. Each <code class="language-plaintext highlighter-rouge">request</code> call extends an internal dependency polytree. For example, the following simplified preparation</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">CovSpec</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">KernelSpec</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">CovSpec</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">KernelSpec</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">Errors</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">Errors</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>
<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">Errors</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">Errors</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">Errors</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>
<span class="n">cache</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="n">Errors</span><span class="p">(</span><span class="n">Ntr</span><span class="p">,</span> <span class="n">Nte</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>produces the following messy polytree (dropping the repetitive declaration of <code class="language-plaintext highlighter-rouge">Ntr</code> and <code class="language-plaintext highlighter-rouge">Nte</code>):</p>

<div class="mermaid">flowchart LR
    MNIST --&gt; Digit_2
    MNIST --&gt; Digit_4
    MNIST --&gt; Digit_5
    Digit_2 &amp; Digit_5 --&gt; TrainTestSplit_2_5
    Digit_4 &amp; Digit_5 --&gt; TrainTestSplit_4_5
    TrainTestSplit_2_5 --&gt; CovSpec_2_5
    TrainTestSplit_4_5 --&gt; CovSpec_4_5
    TrainTestSplit_2_5 --&gt; Kernels_2_5
    TrainTestSplit_4_5 --&gt; Kernels_4_5
    Kernels_2_5 --&gt; KernelSpec_2_5
    Kernels_4_5 --&gt; KernelSpec_4_5
    Kernels_2_5 &amp; TrainTestSplit_2_5 --&gt; Errors_2_5_00
    Kernels_2_5 &amp; TrainTestSplit_2_5 --&gt; Errors_2_5_01
    Kernels_2_5 &amp; TrainTestSplit_2_5 --&gt; Errors_2_5_10
    Kernels_4_5 &amp; TrainTestSplit_4_5 --&gt; Errors_4_5_00
    Kernels_4_5 &amp; TrainTestSplit_4_5 --&gt; Errors_4_5_01
    Kernels_4_5 &amp; TrainTestSplit_4_5 --&gt; Errors_4_5_10
</div>

<p>Each node here represents a file that can be cached for future computations. After the declaration, one calls <code class="language-plaintext highlighter-rouge">fetch</code> to actually start producing the data. This happens in parallel (in the above example in 4 threads). Each of the workers will continuously be assigned new tasks, i.e. new files to produce, according to the following rule:</p>

<blockquote>
  <p>Among all the tasks that haven’t been touched yet look for those which have all dependencies satisfied. Sort them after their tree depth and choose one of those with the highest depth.</p>
</blockquote>

<p>In this way, the algorithm will go deep as fast as possible which also means that the intermediate dependencies can be deleted very timely. In fact, the cached data used was constantly low. In the beginning I have underestimated the size of some objects - even when compressed - which resulted in an “out of disk space” error after the cache contained more than 100 GB of data (not even close to the finish). The same experiment with the new algorithm kept the usage below 2 GB all the time. The clear drawback of this method is the need to write, read, compress and decompress quite frequently. But since RAM usage was constantly at about 4 GB, there is certainly the possibility to keep objects longer (might be added in the future). It is also worth noting, that the computation can be interrupted and restarted without problems since the current cache contains always exactly what is needed for the next steps.</p>

<p>The final code above took about 15 hours to compute on my machine. However, I switched from 3 to 4 cores in the middle of the computation and at that time I also had another intermediate object for a dump of the model, which weighed more than 300 MB when compressed, and whose (de)compression took a considerable amount of computing time. Therefore, I expect the real time to be way less. It will be added here as soon as I have repeated the experiment.</p>

<h2 id="reproduction-of-figures-of-the-paper">Reproduction of Figures of the Paper</h2>

<p>That’s about the original part of this post. Now, only for reference, we’re recreating the figures presented in the paper. Again, the Jupyter notebook can be found in the <a href="https://github.com/lucawellmeier/krrc-mnist-smart-cache">repo</a>.</p>

<h3 id="training-and-test-errors">Training and Test Errors</h3>

<p><img src="/assets/img/train_errors.png" alt="MNIST KRRC training error" /></p>

<p>As expected, the ridgeless regression completely learns the training data …</p>

<p><img src="/assets/img/test_errors.png" alt="MNIST KRRC test errors" /></p>

<p>… but surprisingly the test error curve behaves similarly. In all except one of the digit pairs in the graph above ridgeless regression performs the best. In fact, among all the 45 pairs the following have the best test performance for $\alpha$ very small but not zero: <code class="language-plaintext highlighter-rouge">(1,2)</code>, <code class="language-plaintext highlighter-rouge">(1,4)</code>, <code class="language-plaintext highlighter-rouge">(1,7)</code>, <code class="language-plaintext highlighter-rouge">(4,9)</code>. I suppose this is due to different writing styles of the digits 1, 4 and 7, while the last case is simply the closeness that they might have sometimes.</p>

<h3 id="covariance-and-kernel-spectra">Covariance and Kernel Spectra</h3>

<p><img src="/assets/img/spectrum_covariance.png" alt="MNIST covariance spectrum" /></p>

<p><img src="/assets/img/spectrum_kernel.png" alt="MNIST kernel spectrum" /></p>

<p>Both graphs are reasonably similar to the ones found by the authors, only that the maximal eigenvalues were a little smaller.</p>

  </div>

  <a class="u-url" href="/masters-thesis/2022/04/04/parallel-cached-mnist-krrc.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <ul class="contact-list">
          <li class="p-name">Luca Wellmeier</li>
          <li><a class="u-email" href="mailto:lucwellm@gmail.com">lucwellm@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p>blog about my projects and cv
</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/lucawellmeier" target="_blank" title="lucawellmeier"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
<script>
      mermaid.initialize({ startOnLoad: true });
    </script>
  </body>

</html>
